{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import transformers\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basicPreprocess(text):\n",
    "    processed_text = text.lower()\n",
    "    processed_text = re.sub(r\"[^a-zA-Z0-9]+\", ' ', processed_text)\n",
    "    return processed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_df = pd.read_csv(\"data/clean_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = complete_df.sample(frac = 1).sample(frac = 1)\n",
    "data.dropna(inplace = True)\n",
    "del complete_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[\"abstract\"].apply(basicPreprocess).replace(\"\\n\",\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ''\n",
    "for i in data.values:\n",
    "    text += i\n",
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = Counter(text.split())\n",
    "del text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = []\n",
    "for keys, values in counter.items():\n",
    "    if(values > 100 and values < 10000):\n",
    "        vocab.append(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6737"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained('allenai/scibert_scivocab_uncased')\n",
    "model = transformers.AutoModelWithLMHead.from_pretrained('allenai/scibert_scivocab_uncased').to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertConfig {\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"bert\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"type_vocab_size\": 2,\n",
       "  \"vocab_size\": 31090\n",
       "}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31090\n"
     ]
    }
   ],
   "source": [
    "print(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31941\n"
     ]
    }
   ],
   "source": [
    "tokenizer.add_tokens(vocab)\n",
    "print(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertConfig {\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"bert\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"type_vocab_size\": 2,\n",
       "  \"vocab_size\": 31941\n",
       "}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.resize_token_embeddings(len(tokenizer)) \n",
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "del vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('models/COVID-scibert-tokenizer/vocab.txt',\n",
       " 'models/COVID-scibert-tokenizer/special_tokens_map.json',\n",
       " 'models/COVID-scibert-tokenizer/added_tokens.json')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.mkdir('models/COVID-scibert-tokenizer')\n",
    "tokenizer.save_pretrained('models/COVID-scibert-tokenizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = transformers.LineByLineTextDataset(\n",
    "    tokenizer = tokenizer,\n",
    "    file_path = \"lm_data/train.txt\",\n",
    "    block_size = 64,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = transformers.DataCollatorForLanguageModeling(\n",
    "    tokenizer = tokenizer, mlm = True, mlm_probability = 0.15\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = transformers.TrainingArguments(\n",
    "    output_dir = \"models/COVID-scibert\",\n",
    "    overwrite_output_dir = True,\n",
    "    num_train_epochs = 5,\n",
    "    per_device_train_batch_size = 16,\n",
    "    save_steps = 10_000,\n",
    "    save_total_limit = 3,\n",
    ")\n",
    "\n",
    "trainer = transformers.Trainer(\n",
    "    model = model,\n",
    "    args = training_args,\n",
    "    data_collator = data_collator,\n",
    "    train_dataset = dataset,\n",
    "    prediction_loss_only = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3eca4e4f92484a82aac47488f3d78687",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch', max=5.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c10580710a324cd891cc0a660e641e83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=2259.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"loss\": 2.304284627914429, \"learning_rate\": 4.778663125276671e-05, \"epoch\": 0.2213368747233289, \"step\": 500}\n",
      "{\"loss\": 2.1008607831001282, \"learning_rate\": 4.557326250553343e-05, \"epoch\": 0.4426737494466578, \"step\": 1000}\n",
      "{\"loss\": 2.063936607837677, \"learning_rate\": 4.335989375830013e-05, \"epoch\": 0.6640106241699867, \"step\": 1500}\n",
      "{\"loss\": 2.0148767976760866, \"learning_rate\": 4.114652501106684e-05, \"epoch\": 0.8853474988933157, \"step\": 2000}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "273f652d14044d76a6b24ab837767c83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=2259.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"loss\": 1.9426649825572968, \"learning_rate\": 3.893315626383356e-05, \"epoch\": 1.1066843736166445, \"step\": 2500}\n",
      "{\"loss\": 1.8798881018161773, \"learning_rate\": 3.671978751660027e-05, \"epoch\": 1.3280212483399734, \"step\": 3000}\n",
      "{\"loss\": 1.83592178606987, \"learning_rate\": 3.450641876936698e-05, \"epoch\": 1.5493581230633025, \"step\": 3500}\n",
      "{\"loss\": 1.8167849580049515, \"learning_rate\": 3.229305002213369e-05, \"epoch\": 1.7706949977866313, \"step\": 4000}\n",
      "{\"loss\": 1.7918421647548675, \"learning_rate\": 3.00796812749004e-05, \"epoch\": 1.9920318725099602, \"step\": 4500}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1eb44ec247dd40c1a26ea0c52a9ef5a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=2259.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"loss\": 1.7348681960105896, \"learning_rate\": 2.786631252766711e-05, \"epoch\": 2.213368747233289, \"step\": 5000}\n",
      "{\"loss\": 1.7202716085910796, \"learning_rate\": 2.565294378043382e-05, \"epoch\": 2.434705621956618, \"step\": 5500}\n",
      "{\"loss\": 1.7061260747909546, \"learning_rate\": 2.3439575033200534e-05, \"epoch\": 2.6560424966799467, \"step\": 6000}\n",
      "{\"loss\": 1.691216767191887, \"learning_rate\": 2.1226206285967244e-05, \"epoch\": 2.8773793714032756, \"step\": 6500}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "876d78ce26134ec88095eda58f3cb2c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=2259.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"loss\": 1.6468331438302994, \"learning_rate\": 1.9012837538733954e-05, \"epoch\": 3.098716246126605, \"step\": 7000}\n",
      "{\"loss\": 1.6359560004472733, \"learning_rate\": 1.6799468791500664e-05, \"epoch\": 3.3200531208499338, \"step\": 7500}\n",
      "{\"loss\": 1.6247947722673417, \"learning_rate\": 1.4586100044267376e-05, \"epoch\": 3.5413899955732626, \"step\": 8000}\n",
      "{\"loss\": 1.5908580974340438, \"learning_rate\": 1.2372731297034086e-05, \"epoch\": 3.7627268702965915, \"step\": 8500}\n",
      "{\"loss\": 1.584194672346115, \"learning_rate\": 1.0159362549800798e-05, \"epoch\": 3.9840637450199203, \"step\": 9000}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e69a7b63e2ab4dfabb682d5da4bc17f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=2259.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"loss\": 1.558923286676407, \"learning_rate\": 7.945993802567508e-06, \"epoch\": 4.20540061974325, \"step\": 9500}\n",
      "{\"loss\": 1.5409786819219589, \"learning_rate\": 5.732625055334219e-06, \"epoch\": 4.426737494466578, \"step\": 10000}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tanmay/anaconda3/envs/torch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:200: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.\n",
      "  warnings.warn(SAVE_STATE_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"loss\": 1.5378912506103515, \"learning_rate\": 3.51925630810093e-06, \"epoch\": 4.648074369189907, \"step\": 10500}\n",
      "{\"loss\": 1.5192760183811187, \"learning_rate\": 1.3058875608676407e-06, \"epoch\": 4.869411243913236, \"step\": 11000}\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=11295, training_loss=1.7594639224993438)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"models/COVID-scibert-latest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
